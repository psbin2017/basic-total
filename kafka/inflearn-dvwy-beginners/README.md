# 카프카란?

- 카프카가 무엇인지
- 카프카를 통해서 할 수 있는 일은 어떤 것이 있을지
- 왜 많은 기술 중 카프카를 선택해야하는지

사용자의 요구사항에 따라 필요한 데이터를 적재하게 되었다. 데이터를 전송하는 소스 애플리케이션과 데이터를 소비하는 타겟 애플리케이션을 연결하는 전송 라인이 생기게 된다. 이 연결이 많아지면서 자연스럽게 유지보수가 어려워지는 문제가 발생하게 된다. 이를 극복하기 위해 나타난 것이 카프카다.

카프카의 중요한 핵심은 데이터를 전송하는 소스 애플리케이션과 데이터를 소비하는 타겟 애플리케이션의 약한 결합도(decoupling)에 있다.

# 파티션

파티션은 프로듀서가 레코드를 저장할 때 설정에 따라 선택된 파티션에 레코드를 저장한다.

- 키가 null 이고 기본 파티셔너로 동작: 라운드 로빈으로 레코드를 분배
- 키가 있고 기본 파티셔너로 동작: 키의 해시 값을 구해 파티션을 결정해 레코드를 저장

파티션은 컨슈머가 레코드를 가져갈 때 레코드를 제거하지 않는다. 지정된 설정에 따라서 파티션에 데이터를 제거한다.

- log.retention.ms : 최대 레코드 보존 시간
- log.retention.byte : 최대 레코드 보존 크기 (byte)

파티션을 늘리면 데이터를 분산하여 처리가 가능하다. 그러나 파티션을 늘리는 것은 신중해야한다. 다시 줄일 수 없기 때문이다. (추정으로는 불가능은 아닌데 어려운게 아닐지..?)

# ISR (In-Sync-Replication)

카프카 운영에 있어 중요한 개념이다. 카프카는 장애를 극복하기 위해 파티션을 복제하여 저장할 수 있다. 이 복제된 상태의 파티션을 ISR 상태라고 할 수 있다.

- 브로커: 3, 파티션: 1, 리플리케이션: 1 ==> 1개의 브로커에 저장
- 브로커: 3, 파티션: 1, 리플리케이션: 2 ==> 1개의 브로커에 레코드를 파티션에 저장하고 복제된 레코드를 다른 브로커의 파티션에 레코르를 저장
- 브로커: 3, 파티션: 1, 리플리케이션: 3 ==> 1개의 브로커에 레코드를 파티션에 저장하고 복제된 레코드를 다른 2개의 브로커의 파티션에 레코드를 저장

복제된 데이터를 가진 파티션은 팔로워 파티션이라고 하고 원본 데이터를 가진 파티션을 리더 파티션이라고 한다.

리플리케이션은 브로커보다 커질 수 없다.

## ACK

프로듀서가 레코드를 전달하고 파티션의 상태를 확인하는 상태를 ACK 라고 하며 0 / 1 / ALL 이 있다.

- ACK 0: 레코드를 전달하고 파티션의 응답을 기다리지 않는다.
- ACK 1: 레코드를 전달하고 리더 파티션의 응답을 기다린다.
- ACK ALL: 레코드를 전달하고 리더 파티션과 팔로워 파티션 모두의 응답을 기다린다.

0 일 수록 빠른 속도를 보장하지만 레코드가 유실될 수 있다. 반대로 ALL 일 수록 레코드를 보장하지만 대기하기 때문에 느려진다.

# 파티셔너

프로듀서가 레코드를 전송할 때 반드시 파티셔너를 통해서 브로커로 전송된다.

파티셔너는 어떤 파티션에 저장할지를 결정한다.

## UniformStickyPartitioner : Default

메시지 키의 유무에 따라 파티션이 결정된다.

- 메시지 키 O: hash(meesage key)
- 메시지 키 X: 라운드 로빈으로 적재. 단, 배치 단위로 데이터를 모은다.

동일한 메시지 키를 가진 것은 동일한 파티션에 들어가는 것을 보장하여 순서를 지켜 처리를 할 수 있게 된다.

## Partitioner 인터페이스

사용자가 원하는 방식에 따라 파티셔너를 커스터마이징하게 구현할 수 있다. 메시지 값, 토픽 이름 등으로 구현할 수 있다.

# 컨슈머 랙

> 프로듀서가 파티션에 래코드를 저장한 오프셋 - 컨슈머가 파티션에 레코드를 가져간 오프셋 = 컨슈머 랙

토픽에 여러 파티션이 있다면 각각 컨슈머 랙이 측정되고 여러개 존재하는 컨슈머 랙 중 가장 큰 값을 레코드 랙 맥스(record lag max)라고 부른다.

# 버로우 : Burrow

컨슈머 랙 모니터링을 도와주는 애플리케이션이다.

- 멀티 카프카 클러스터 지원
- 슬라이딩 윈도우를 통한 컨슈머 상태를 표현 (WARNING / ERROR / OK)
- HTTP API 제공

# 브로커

메시지 브로커는 이벤트 브로커가 될 수 없지만, 이벤트 브로커는 메시지 브로커가 될 수 있다.

## 메시지 브로커

> 레빗엠큐 / 레디스큐

메시지 브로커는 컨슈머가 소비하고 나면 즉시/짧은 지연 후 데이터가 삭제되는 구조이다.

## 이벤트 브로커

> 카프카 / 키네시스

레코드를 하나만 보관하고 인덱스를 통해 개별 액세스를 보장하고 또한 데이터를 삭제하지 않는다.

## 컨슈머

컨슈머는 각 파티션에 대한 오프셋을 가지고 있으며 중도에 컨슈머가 실행이 중지되어 재실행 되어도 오프셋부터 실행된다. (__consumer_offsets)

파티션 : 컨슈머 상황 예제

- 파티션2 : 컨슈머1 ==> 컨슈머1 이 파티션2를 가져간다.
- 파티션2 : 컨슈머2 ==> 각각 일대일 매칭되어 가져간다.
- 파티션2 : 컨슈머3 ==> 한 개의 컨슈머가 동작하지 않는다. (나머지는 일대일 동작)

따라서 컨슈머의 개수는 파티션의 개수보다 적을 것을 권장한다.

- 파티션2 : 컨슈머2 그룹A : 컨슈머2 그룹B ==> 각각 그룹 A, B 에 일대일 매칭되어 가져간다.

따라서 컨슈머 그룹이 다르다면 데이터를 읽는데 영향을 미치지 않는다.

이는 컨슈머 그룹별로 오프셋을 저장하기 때문이다.

# 스트림즈

카프카의 공식 라이브러리. JVM 기반 플랫폼에서는 사용 가능하며 카프카와 완벽 호환 된다. 카프카가 릴리스 될 때마다 같이 패치되서 얻는 이점이 많다.

Streams DSL 과 Processor API 를 제공하여 사용할 수 있다. 다만 DSL 강력하여 대다수의 상황은 DSL 로도 극복 가능하다. (고 한다.)

# 커넥터

카프카의 공식 컴포넌트로 커넥트와 커넥터 두 가지의 개념이 있다.

- 커넥트: 커넥터를 동작하도록 하기 위한 실행 도구
- 커넥터: 실제 동작하는 실행 코드

커넥터는 싱크 커넥터와 소스 커넥터로 구분된다.

- 싱크 커넥터: 데이터를 다른 벤더에 저장하는 역할을 하는 커넥터
- 소스 커넥터: 다른 벤더에서 가져와 데이터를 카프카에 저장하는 커넥터

커넥트는 단일 모드 커넥트와 분산 모드 커넥터로 구분된다.

- 단일 모드 커넥트: 개발용으로 사용하는 편
- 분산 모드 커넥트: 카프카 커넥트를 클러스터로 묶인 형태로 fail over 에 안전하다.